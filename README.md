# Charisma-Predictor: Multi-Modal AI for Personality & Leadership Assessment

This project builds a multi-modal AI pipeline to estimate **Big Five personality traits** from **audio, video, and text**, and to map those traits to a **charismatic leadership score**. It was developed as part of an MSc AI group project at Maastricht University.

ğŸ§  This GitHub repository includes **only the parts I personally implemented**: the **video model**, the **fusion system**, and the **leadership scoring + visualization**.

---

## ğŸš€ Highlights

* ğŸ¥ Video: facial landmark tracking via MediaPipe + five sequence models (CNN, LSTM, GRU, Transformer, TCN)
* ğŸ¤– Video outputs ensembled via weighted averaging (best MAE: 0.1189)
* ğŸ”€ Fusion: weighted averaging and Multi-Channel Weighted Fusion (MCWF)
* ğŸ“ˆ Output: Big Five personality prediction + charisma score âˆˆ \[0, 1] with classification (Very Low â†’ Very High)
* ğŸ“Š Visualization of leadership score distribution and model performance
* âœ… Achieved up to **92.45% accuracy** on Big Five personality traits via fusion model (MCWF)

---

## ğŸ“Š Sample Output

**Leadership Suitability Distribution:**

![Leadership Histogram](figures/Leadership Suitability Distribution, true label vs. prediction.png)

**Fusion Model Personality Accuracy (MCWF):**

![Fusion Confusion Matrix](figures/confusion matrics_fusion.jpg)

---

## ğŸ‘¤ My Contribution

This repository reflects the parts of the project I directly implemented:

* Developed the full **video model** pipeline: feature extraction, five-model architecture (CNN, LSTM, GRU, Transformer, TCN), ensemble fusion, evaluation
* Designed and implemented **fusion logic**, including simple averaging, weighted fusion, and trait-specific MCWF
* Developed the charisma scoring system based on normalized Big Five correlations
* Produced evaluation results, metrics, and visualizations (e.g., final histograms)

---

## ğŸ“ Project Structure

```
charisma-predictor/
â”œâ”€â”€ video_model/            # My code for facial landmark + sequence model ensemble
â”œâ”€â”€ fusion/                 # My code for fusion logic (weighted avg, MCWF)
â”œâ”€â”€ figures/                # Output plots (confusion matrices, histograms)
â”œâ”€â”€ results/                # Personality predictions + charisma scores
â”œâ”€â”€ text_and_audio/         # References to group members' implementations
â”‚   â””â”€â”€ README.md           # External links only (not my code)
â”œâ”€â”€ report_links/           # Final team report PDF link
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ README.md               # You're reading it
â””â”€â”€ requirements.txt
```

---

## ğŸ“ Related Work by Team Members

While I did not implement the audio and text models, they contributed to the fusion output. You can find their work here:

* ğŸ“„ [Full project report (PDF)](https://drive.google.com/file/d/1LQnHQryJfcT02PuWKHqSIbIRdy0jVY7T/view?usp=sharing)
* ğŸ”Š [Audio model code & description](https://drive.google.com/drive/folders/1SoNqgf6J3f-QCa_LvFf0fSnW1xZLOgCV?usp=drive_link)
* ğŸ“ [Text model code & description](https://drive.google.com/drive/folders/1npBfmOsTbw5ziEsa_PnD_drb8xST2BSP?usp=drive_link)

---

## ğŸ› ï¸ Run the Fusion Module

```bash
pip install -r requirements.txt
python fusion/run_mcwf.py
```

---

## ğŸ“„ Dataset

* [First Impressions Dataset](https://chalearnlap.cvc.uab.cat/dataset/20/description/) â€“ 10,000 annotated video clips

---

## ğŸ§  Methodology Summary

* Video: MediaPipe landmark sequences â†’ five models (CNN, LSTM, GRU, Transformer, TCN) â†’ trait-level scores â†’ ensembled via weighted average
* Audio/Text: pretrained AST / BERT models â†’ Big Five scores (via linked repos)
* Fusion: average, weighted, MCWF â†’ leadership score mapping (0â€“1)
* Classification into 5 buckets: Very Low â†’ Very High suitability

---

## ğŸ“Œ Final Grade

This project received a final mark of **8.5 / 10**.

---

## âš ï¸ Disclaimer

This repository contains only the work I personally implemented. Please refer to linked resources for other group contributions.
